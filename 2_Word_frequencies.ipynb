{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's in an online dating profile? \n",
    "\n",
    "## Contents\n",
    "1. [Setup](#Section-1%3A-Setup)\n",
    "    1. [Import](#1.1-Import-Packages)\n",
    "    1. [Download](#1.2-Download-and-Prepare-Data)\n",
    "    1. [Read](#1.3-Read-Data)\n",
    "    1. [For Laptop Users](#1.4-For-Laptop-Users)\n",
    "    1. [Helper Functions](#1.5-Helper-Functions)\n",
    "1. [Tokenizing Text](#Section-2%3A-Tokenizing-Text)\n",
    "    1. [Simple First Try](#2.1-Simple-First-Try)\n",
    "    1. [Stop Words](#2.2-Stop-Words)\n",
    "    1. [Better-Tokenizing](#2.3-Beter-Tokenizing)\n",
    "1. [Word Use and Gender](#Section-3%3A-Word-Use-and-Gender)\n",
    "1. [Stemming](#Section-3%3A-Stemming)\n",
    "1. [Try another Trait](#Section-4%3A-Try-another-Trait)\n",
    "1. [What We Learned](#Section-5%3A-What-We-Learned)\n",
    "\n",
    "## Section 0: Background\n",
    "People say a lot about themselves in online dating profiles, especially on sites like OKCupid that encourage people to answer questions. Thus, we can learn a lot about people by studying what they write. OKC has made some of their profile data from San Francisco public. We will be using that data in this lab to explore different cultural questions. \n",
    "\n",
    "Our first question is whether and how men and women talk about themselves differently in their profiles. Popular culture is constantly telling us that men and women have different interests, hobbies, and relationship goals. Yet there are also many examples of women who like stereotypically masculine things and men who like feminine ones. This is especially interesting in online dating, because people are seeking partners with similar interests and relationship goals. Finding a partner would be hard for straight men and women if these two groups had very different interests. \n",
    "\n",
    "OKC shared 59,946 profiles though -- way too many to read! Computers can read them all and tell us how common different words are. So our first approach will be simple. We can ask \n",
    "1. Which words are used the most by men and women? \n",
    "2. Which words are used often by men but not women, and vice versa? \n",
    "\n",
    "### 0.1 Learning Objectives\n",
    "At the end of the lab, you'll be able to ask this question about other social groups too (like sexual orientation, race/ethnicity, age, level of education, even whether someone likes dogs or cats).\n",
    "\n",
    "@Author: [Jeff Lockhart](http://www-personal.umich.edu/~jwlock/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup\n",
    "### 1.1 Import Packages\n",
    "- Packages contain a bunch of useful code others have written to make our jobs easier.\n",
    "- `tqdm.pandas()` shows progress bars for some slower things.\n",
    "- `nltk.download()` makes sure the `nltk` package has everything it needs. If you have run it before, you can add a `#` at the start of that line to skip it.\n",
    "- `%matplotlib inline` lets us see charts and plots right here in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required packages\n",
    "!pip install nltk\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import nltk\n",
    "# If you have used NLTK or run this code before, you can comment out this download line\n",
    "nltk.download('popular', quiet=True)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download and Prepare Data\n",
    "This code checks whether you have the data. If you don't, it will download and prepare it for you. To see how it works, look at lab `1 Data munging` which explains it in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'download_and_clean_data.py'\n",
    "print('Ready to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('data/clean_profiles.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show how many rows and columns the data has\n",
    "profiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the names of the columns\n",
    "profiles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the first few rows of data\n",
    "profiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 For Laptop Users\n",
    "Run this code so that you're working with a smaller amount of data and don't crash your computer. It takes a simple random sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles.sample(10000)\n",
    "profiles = profiles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Helper Functions\n",
    "- While we're at it, let's make some helper functions for later.\n",
    "- Run this code, but don't worry about these now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_example(text, word, context=False):\n",
    "    #regex for selecting the whole word from a stem\n",
    "    expr = word + '\\w*'\n",
    "    \n",
    "    if context:\n",
    "        #regex for selecting a stem and also the 2 words before and after it\n",
    "        #this lets us see the context in which it is used\n",
    "        expr = '\\w*\\W*\\w*\\W*' + word + '\\w*\\W*\\w*\\W*\\w*'\n",
    "\n",
    "    return re.search(expr, text, re.I).group()\n",
    "\n",
    "def get_examples(data, word, n=5, context=True, limit_col=None, limit_val=None):\n",
    "    if word.endswith('i'):\n",
    "        #the Porter2 stemmer sometimes adds 'i' to stems. This trimms it off.\n",
    "        word = word[:-1]\n",
    "    \n",
    "    #restrict to just some group of interest\n",
    "    if limit_col is not None:\n",
    "        data = data[data[limit_col] == limit_val]\n",
    "    \n",
    "    #sample our data so this operation goes faster\n",
    "    if data.shape[0] > 1000:\n",
    "        data = data.sample(1000)\n",
    "    \n",
    "    #find profiles with the word in them\n",
    "    tmp = data.text.apply(lambda x: word in x)\n",
    "    #select n random profiles that have the word\n",
    "    count = tmp.sum()\n",
    "    \n",
    "    #if we wanted more examples than there are\n",
    "    if n > count:\n",
    "        n = count\n",
    "    tmp2 = data[tmp].text.sample(n).values\n",
    "    \n",
    "    #get an example out of each profile we selected\n",
    "    tmp = []\n",
    "    for t in tmp2:\n",
    "        tmp.append(extract_example(t, word, context))\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "def unstem(word, data, n=50):\n",
    "    if word.endswith('i'):\n",
    "        #the Porter2 stemmer sometimes adds 'i' to stems. This trimms it off.\n",
    "        word = word[:-1]\n",
    "\n",
    "    try:\n",
    "        #use the function we made before to get examples of the stem\n",
    "        tmp = get_examples(data, word=word, n=n, context=False)\n",
    "        \n",
    "        #count up and return the most common form of the word matching the stem\n",
    "        result = Counter(tmp).most_common(1)[0][0]\n",
    "    except:\n",
    "        result = word\n",
    "    \n",
    "    return result\n",
    "\n",
    "def clean_index(df, text):\n",
    "    #replaces stems in the index of a dataframe with whole words\n",
    "    df.reset_index(inplace=True)\n",
    "    df['index'] = df['index'].progress_apply(unstem, data=text)\n",
    "    df.set_index('index', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Tokenizing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Simple First Try\n",
    "#### Let's peak at an example of the text so we know what we're working with.\n",
    "This code shows us the text for the 6th profile (python counts from 0, so the first profile is #0, the second is #1, and so on). 5 here could be any number. Try changing it to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.text[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to split the text into words so we can count them. Here's a simple first try.\n",
    "- The `split()` function, like its name suggests, splits text into chunks. If we split on spaces (the default), it will split the text into words. Let's `apply` it to the `text` of our `profiles`.\n",
    "- Notice that this is a little messy. The punctuation and some HTML things are mixed in with our words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = profiles['text'].apply(lambda x: x.split())\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at the most common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = Counter(chain.from_iterable(tmp))\n",
    "tmp.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short answer: types of words\n",
    "- There are many different types of words in English. We have nouns, pronouns, adjectives, verbs, adverbs, conjunctions, prepositions, articles, and more!\n",
    "- Notice above that many of the most common words are prepositions, conjunctions, and articles (\"the,\" \"a,\" \"but,\" \"of,\" \"to,\" etc.). \n",
    "- Looking at how people use different types of words can be informative. For instance, [some research](http://www.yalescientific.org/2012/03/the-secret-life-of-pronouns) has shown that depressed poets use more first-person pronouns (e.g. \"I\") than others. Thus we might be able to study pronoun use as a way to measure the emotions of authors.\n",
    "- Think of other possible examples. For each of the questions below, tell us what kinds of words might help us answer the question and why.\n",
    "    - What *things* is an author writing about?\n",
    "    - What is an author's mood or feeling about the thing they're discussing?\n",
    "    - How educated is an author?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔 **Write your answers here:**\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Stop Words\n",
    "- Researchers often decide to ignore some types of words that they think won't help answer the question they are asking. These are called \"stop words.\" It is common to remove them so we can focus on the words we think matter. [Learn more](https://en.wikipedia.org/wiki/Stop_words)\n",
    "- The common set of stop words for English includes conjunctions, prepositions, articles, and pronouns. Basically, these are the small filler and connector words that we have to use all the time. This set of words is so common that it is built in for people to use. \n",
    "    - This lab makes an exception to the normal list of stop words and keeps the pronouns, because some research shows that pronoun use matters in dating. You could add more words to remove or keep, depending on what you think is important, but we will use these for the lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show stop word list\n",
    "sw = set(stopwords.words('english'))\n",
    "print('Here is the list of common English stop words:\\n\\n', sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "              'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "              'himself', 'she', 'her', 'hers', 'herself', 'they', 'them', 'their',\n",
    "              'theirs', 'themselves']\n",
    "\n",
    "for k in keep_words:\n",
    "    sw.discard(k) #could use remove if we wanted keyerrors\n",
    "    \n",
    "print(\"Here are the words we will remove:\\n\\n\", sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Better Tokenizing\n",
    "- In the most common words, we also saw some messy stuff like `\\>`.\n",
    "- This code cleans the text up a bit. \n",
    "    - We remove all the HTML code from the text\n",
    "    - We remove some other non-word text like \"www\"\n",
    "    - We convert all the text to lowercase, so that the computer sees \"Dog\", \"DOG\", and \"dog\" as the same word.\n",
    "    - We remove all our stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, sw):\n",
    "    t = BeautifulSoup(text, 'lxml').get_text()\n",
    "    \n",
    "    bad_words = ['http', 'www', '\\nnan']\n",
    "    for b in bad_words:\n",
    "        t = t.replace(b, '')\n",
    "    \n",
    "    t = t.lower()\n",
    "    t = regexp_tokenize(t, '\\w+')\n",
    "    \n",
    "    final = []\n",
    "    for w in t:\n",
    "        if w not in sw:\n",
    "            final.append(w)\n",
    "    \n",
    "    return final\n",
    "\n",
    "profiles['tokens'] = profiles['text'].progress_apply(clean, sw=sw)\n",
    "profiles.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Word Use and Gender\n",
    "#### Step 1: We separate the profiles of women and men.\n",
    "We'll limit it to straight people for now. You'll have the chance to explore other groups later in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = profiles[(profiles['sex'] == 'm') & (profiles['orientation'] == 'straight')]\n",
    "women = profiles[(profiles['sex'] == 'f') & (profiles['orientation'] == 'straight')]\n",
    "\n",
    "men.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Counting how often each gender uses each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this counts how many times each word shows up\n",
    "mens_words = Counter(chain.from_iterable(men.tokens)) \n",
    "\n",
    "print('Ten most common words used by men:')\n",
    "mens_words.most_common(10) #this shows us the 10 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ten most common words used by women:')\n",
    "womens_words = Counter(chain.from_iterable(women.tokens))\n",
    "womens_words.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the most popular words are basically the same for each gender.\n",
    "\n",
    "#### Step 3a: Put the word counts in a data frame so they're easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the two word count data into a single dataframe so it's easy to work with \n",
    "tmp = {'women': womens_words, 'men': mens_words}\n",
    "popular_words = pd.DataFrame(tmp)\n",
    "\n",
    "#this cleans it up a bit by putting in 0 for all the words we didn't see\n",
    "popular_words = popular_words.fillna(0).astype(int)\n",
    "\n",
    "popular_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the words are sorted alphabetically. That's not super useful, though.\n",
    "\n",
    "#### Step 3b: Sort the words by popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='women', ascending=False)\n",
    "popular_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Convert those word counts to frequencies (percent of total words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the word counts into percents (i.e. what percent of total words are x)\n",
    "popular_words['men'] = (popular_words['men'] /  popular_words['men'].sum())*100\n",
    "popular_words['women'] = (popular_words['women'] /  popular_words['women'].sum())*100\n",
    "\n",
    "#create a column \"max\" that has the word's maxmum popularity (in either men or women)\n",
    "popular_words['max'] = popular_words.max(axis=1)\n",
    "\n",
    "#show the most popular words overall\n",
    "popular_words.sort_values(by='max', ascending=False, inplace=True)\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see some typical examples of how these words are used\n",
    "- You can change the number `6` to show more or less examples.\n",
    "- The examples are picked at random each time you run the code. So if you run it more than once, you will see different examples.\n",
    "- You can change the world `'love'` to any word you're interested in. \n",
    "    - \"love\" is interesting because it is not always used the way we might expect in a dating profile. \n",
    "    \n",
    "#### Short Answer\n",
    "- Pick a word (you can use \"love\" if you want) and run the code in the cells below a few times to get examples of that word. \n",
    "- In a few sentences, tell us what word you picked and at least two different meanings it has or two different ways it gets used. Give examples from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_examples(data=profiles, word='love', n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can look at just examples from men or from women using this code:\n",
    "- You can change `limit_col` to something other than `sex` if you want to look at a different attribute.\n",
    "- You can change `limit_val` to something other than `m` if you want to look at a different group within the attribute (e.g. change it to `f` if you want to see women's use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_examples(data=profiles, word='love', n=6, limit_col='sex', limit_val='f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔 **Write your response here:**\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most words are very uncommon\n",
    "- The X axis in this histogram is the word popularity (percent of total words that are this word). \n",
    "- The Y axis is the number of words that have that level of popularity.\n",
    "- For example, we saw above that the word \"I\" makes up about 8% of all words in our data. In the chart, this shows up as a bar at 8 on the x axis. The bar is really short because only one word is that popular. By contrast, the bars on the far left are really big ($10^5 = 100,000$), which means that there are a *lot* of words that are very rare in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show a histogram with 100 bins\n",
    "popular_words['max'].plot.hist(bins=100, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Look at just the 1,000 most popular words\n",
    "- Note that the shape of the distribution looks similar, but the Y axis is much smaller ($ 10^3 $ instead of $ 10^5 $), meaning we have removed many extremely uncommon words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only the 1000 most popular words\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False).head(1000)\n",
    "\n",
    "#show the histogram again\n",
    "popular_words['max'].plot.hist(bins=100, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Figure out which words are more popular with one gender than the other\n",
    "- Here we calculate how many times different the usage of words by men or women is, so if men use a word twice as often as women use the same word, then men's use is 2 times different. \n",
    "- Like we saw before, both groups use the most popular words about the same amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_diff(row):\n",
    "    #calculate how many times more men use a word than women\n",
    "    #or vice versa if women use the word more\n",
    "    if row.men > row.women:\n",
    "        return row.men / row.women\n",
    "    else:\n",
    "        return -1 * (row.women / row.men)\n",
    "    \n",
    "popular_words['times_diff'] = popular_words.apply(times_diff, axis=1)\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "\n",
    "print('Most popular words:')\n",
    "popular_words.head(10).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at the words that are most different between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Words men use more than women:')\n",
    "popular_words.sort_values(by='times_diff', ascending=False).head(15).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Words women use more than men:')\n",
    "popular_words.sort_values(by='times_diff', ascending=True).head(15).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer: repeated words\n",
    "- Do you see any words that show up more than once in the lists above? It is possible that both \"computer\" and \"computers\" show up for men (San Francisco men really like to talk about computers...)\n",
    "- Repeated words happen a lot. We know those are the same word, but to the computers they are different. Computers are very literal, so because the words \"computer\" and \"computers\" don't have exactly the same letters in exactly the same order, it thinks they are different. \n",
    "- Reflect: give one or two examples of times this might happen, other than plural words with an \"s\" added on the end. Write full sentences.\n",
    "    - Hint: look at the word lists above, and/or think about other word endings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔 **Write your response here:** \n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with word endings\n",
    "- When researchers want to match words that have the same base but different endings, they do something called \"stemming.\" \n",
    "- Stemming grabs just the \"stem\" of each word (e.g. the stem of both \"run\" and \"runs\" is \"run\"). When the words are converted to their stems, the computer sees them as the same. [Learn more](https://en.wikipedia.org/wiki/Stemming)\n",
    "- Stemming English is a little complicated, because English spelling has so many quirks. Luckily, experts have already done the hard work for us. We can use their tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snowball English (aka porter2) is the best general stemmer\n",
    "stemmer = SnowballStemmer(\"english\") \n",
    "\n",
    "def stem(t):\n",
    "    out = []\n",
    "    for w in t:\n",
    "        out.append(stemmer.stem(w))\n",
    "    return out\n",
    "\n",
    "print(\"Stemming words from profile text...\")\n",
    "profiles['stems'] = profiles['tokens'].progress_apply(stem)\n",
    "profiles.drop(columns=['tokens'], inplace=True)\n",
    "profiles.stems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These helper functions let us do the same things we did before without rewriting all the steps each time.\n",
    "You don't have to worry about what's in them right now. Just run the cell and scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for summarizing word use by a trait\n",
    "def times_diff2(row, group, ref):\n",
    "    if row[ref] > row[group]:\n",
    "        return -1 * (row[ref] / row[group])\n",
    "    else:\n",
    "        return row[group] / row[ref]\n",
    "\n",
    "def count(data, per_person):\n",
    "    #count the people in each category\n",
    "    l = len(data)\n",
    "\n",
    "    #apply the right aggregation function, depending whether we want \n",
    "    #most common words, or words used by most people\n",
    "    if per_person:\n",
    "        data = chain.from_iterable([set(x) for x in data])\n",
    "    else:\n",
    "        data = chain.from_iterable(data)\n",
    "            \n",
    "    c = Counter(data)\n",
    "    \n",
    "    return c, l\n",
    "\n",
    "def word_use(df, att, ref=None, per_person=False, undostems=False):\n",
    "    #list all of the categories in this column\n",
    "    types = list(df[att].value_counts().index.values)\n",
    "    #variables that will store our results\n",
    "    data = {}\n",
    "    lens = {}\n",
    "    \n",
    "    print(\"Counting the words used by each group...\")\n",
    "    for t in types:\n",
    "        #get the stems for each category\n",
    "        tmp = df[df[att] == t].stems\n",
    "        #count how often each is used\n",
    "        data[t], lens[t] = count(tmp, per_person)\n",
    "        \n",
    "        #also compute the inverse of each category\n",
    "        tmp = df[df[att] != t].stems\n",
    "        data['not_'+str(t)], lens['not_'+str(t)] = count(tmp, per_person)        \n",
    "        \n",
    "    #convert those results to a pandas data frame for easy handling\n",
    "    popular_words = pd.DataFrame(data)\n",
    "    \n",
    "    print('Calculating percentages...')\n",
    "    # convert the counts in each column to percents\n",
    "    print(popular_words.head())\n",
    "    for t in popular_words.columns:\n",
    "        n = lens[t] #if we want percent of people\n",
    "        \n",
    "        if not per_person: #if we want percent of total words \n",
    "            n = popular_words[t].sum()\n",
    "        #else:\n",
    "        #    n = popular_words[t].sum()\n",
    "        \n",
    "        popular_words[t] = (popular_words[t] / n) * 100\n",
    "    \n",
    "    print('Selecting the most popular words...')\n",
    "    #find overall most popular words\n",
    "    popular_words['max'] = popular_words.max(axis=1)\n",
    "    #sort the words and select the top 1000 most popular\n",
    "    popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "    popular_words = popular_words.head(1000)\n",
    "\n",
    "    print('Calculating most distinctive words...')\n",
    "    #calculate the rate each type of person uses these words relative to others\n",
    "    for t in types:\n",
    "        r = ref\n",
    "        \n",
    "        if ref == None: #if we do not have a reference category, use the inverse\n",
    "            r = 'not_'+str(t)\n",
    "            \n",
    "        if t != ref: #don't compare a trait to itself\n",
    "            #apply our times_diff2 function\n",
    "            popular_words['times_diff_'+str(t)] = popular_words.apply(times_diff2, \n",
    "                                                                 group=t, \n",
    "                                                                 ref=r, \n",
    "                                                                 axis=1)\n",
    "\n",
    "    #remove the inverse columns we created\n",
    "    popular_words = popular_words.drop(popular_words.filter(regex='not_'), axis=1)\n",
    "    \n",
    "    if undostems:\n",
    "        print('Cleaning up word stems for readability...')\n",
    "        popular_words = clean_index(popular_words, df)\n",
    "    \n",
    "    print('Done!')\n",
    "    return popular_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try comparing men's and women's words again with stems this time\n",
    "- The top words are somewhat different now that we're counting similar words as the same.\n",
    "- We see word stems rather than whole words listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex')\n",
    "popular_words = popular_words.sort_values(by='times_diff_m', ascending=False)\n",
    "print(\"Men's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Those word stems in our table are a little hard to read. Let's change that.\n",
    "- The `undostems=True` option converts the stems back to whole words before showing us the result.\n",
    "\n",
    "#### Short answer:\n",
    "- Now that we have combined all the different versions of each word using stems (e.g. \"run\", \"running\", and \"runs\" are all counted as \"run\" now), did the top words change? Are there new words in the top, or a different order to the old words? In a few sentences each, pick two differences you see from before and after stemming, say what they are, and explain why you think they changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', undostems=True)\n",
    "popular_words = popular_words.sort_values(by='times_diff_m', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Men's distinctive words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=False)\n",
    "print(\"Women's distinctive words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔 **Write your response here:** \n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer:\n",
    "- Up to now, we have looked at how many times each word was used, out of all the words used by all the people.\n",
    "- What ff a single man wrote the word \"computer\" a thousand times? Because we are just counting how many times the word was used, it would look the same to us as if a thousand men had each used the word one time. \n",
    "- Next, we're going to look at how many different people use each word at least one time, using `per_person=True`.\n",
    "- Look for differences between the latest results, counting how many people use each word, and the earlier results, counting how many times each word was used. (Hints: Are there different words in the top 10? Did their order change? Did the percents change?)\n",
    "- Pick two things that are different. In a few sentences each, tell us what the difference is and what you think it means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', per_person=True, undostems=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Men's words:\")\n",
    "popular_words.sort_values(by='times_diff_m', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Women's words:\")\n",
    "popular_words.sort_values(by='times_diff_f', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔 **Write your responses here:**\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Try another Trait\n",
    "#### Options (traits)\n",
    "We have a lot more information about people than just whether they're men or women. Try the analysis again with one of these other traits. (Expand for a list.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- age_group (How old someone is. Youngest users are 18.)\n",
    "    - categories: ['10', '20', '30', '40', '50']\n",
    "- body (self-described)\n",
    "    - categories: ['average', 'fit', 'thin', 'overweight', 'unknown']\n",
    "- alcohol_use\n",
    "    - categories: ['yes', 'no']\n",
    "- drug_use\n",
    "    - categories: ['yes', 'no']\n",
    "- edu (highest degree completed)\n",
    "    - categories: ['`<HS`', 'HS', 'BA', 'Grad_Pro', 'unknown'] \n",
    "- race_ethnicity\n",
    "    - categories: ['Asian', 'Black', 'Latinx', 'White', 'multiple', 'other']\n",
    "- height_group (whether someone is over or under six feet tall)\n",
    "    - categories: ['under_6', 'over_6']\n",
    "- industry (what field they work in)\n",
    "    - categories: ['STEM', 'business', 'education', 'creative', 'med_law', 'other'] \n",
    "- kids (whether they have children)\n",
    "    - categories: ['yes', 'no']\n",
    "- orientation\n",
    "    - categories: ['straight', 'gay', 'bisexual']\n",
    "- pets_likes (what pets they like)\n",
    "    - categories: ['both', 'dogs', 'cats', 'neither']\n",
    "- pets_has (what pets they have)\n",
    "    - categories: ['both', 'dogs', 'cats', 'neither']\n",
    "- pets_any (whether they have pets or not)\n",
    "    - categories: ['yes', 'no']\n",
    "- religion\n",
    "    - categories: ['christianity', 'catholicism', 'judaism', 'buddhism', 'none', 'other'] \n",
    "- sex\n",
    "    - categories: ['m', 'f']\n",
    "- smoker\n",
    "    - categories: ['yes', 'no']\n",
    "- languages\n",
    "    - categories: ['multiple', 'English_only'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to (steps)\n",
    "#### Step 1a: Decide which of the traits above you want to look at.\n",
    "#### Step 1b: Load the profile data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('data/clean_profiles.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2a: If you want, limit the data to just men or women.\n",
    "- For everyone, leave this code how it is.\n",
    "- For only men, remove the `#`\n",
    "- For only women, remove the `#` and change the `'m'` in this line to `'f'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profiles = profiles[profiles['sex'] == 'm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2b: Sampling for Efficiency \n",
    "Run this code to use just a sample of the data set, because the full data is big enough to crash most personal computers. You can make the sample bigger or smaller by changing the number here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles.sample(10000)\n",
    "profiles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Tokenize and stem the text for these profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizing...\")\n",
    "profiles['tokens'] = profiles['text'].progress_apply(clean, sw=sw)\n",
    "print(\"Stemming...\")\n",
    "profiles['stems'] = profiles['tokens'].progress_apply(stem)\n",
    "profiles.drop(columns=['tokens'], inplace=True)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Compute the word usage statistics for your chosen attribute.\n",
    "You can change the code below:\n",
    "- You can change `att='age_group'` to your attribute of interest (e.g. `pets_likes` or `orientation`)\n",
    "- The `per_person` and `undostems` are the same as we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='pets_likes', per_person=True, undostems=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5a: Look at the results.\n",
    "First, let's just see what columns we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(2).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5b: Looking at the most distinctive words by category\n",
    "You can change two things in this code:\n",
    "1. Change `'times_diff_dogs'` to the name of the column you want to sort by, i.e. the column you want to see the most popular words in. \n",
    "2. Change the number in `head(10)` to a bigger or smaller number to see more or less rows of output.\n",
    "\n",
    "You can paste this line into more cells below and change it again to show different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_dogs', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_cats', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_neither', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_both', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: What We Learned\n",
    "Expand for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sociology & Gender\n",
    "1. Overall, the most common words in online dating are the same for men and women in San Francisco. What they say about themselves is not that different. \n",
    "2. There are some words that men use much more often than women, and vice versa. These fit stereotypical gender roles: for example, men in San Francisco are much more likely to talk about computers, startups, engineering, and sports. And women are much more likely to talk about food (e.g. baking and chocolate) or feelings (adore, laughter). \n",
    "3. There are many possible causes for these differences in word use. For example, it is often taboo for men to talk about their feelings, so they may mention them less here because of social expectations rather than because they are less emotional. Social factors can also increase expression: for instance, women typically do the majority of food preparation in American families, so it is not surprising that they are more likely than men to talk about it in dating profiles. \n",
    "4. Not every person conforms to these broad patterns. Only 10-20% of these men mention computers. A similar percent of the women mention baking. Some women talk about computers, and some men talk about baking. Most people aren't using these very gendered words at all. What we showed is that there are broad patterns of some topics being much more popular with men or women, and that these patterns line up with common cultural expectations of gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analysis\n",
    "1. **Tokenizing** is the process of splitting text into words (tokens). Simple approaches can separate words based on spaces, but punctuation, HTML, and other things can make this more complicated. \n",
    "2. **Stop words** are words that are common but don't give us much information. They're often removed before we do analysis.\n",
    "3. **Stemming** lets us combine similar words like \"runs\" and \"running\" by looking at the stem of the words (in this case, \"run\"). \n",
    "4. Most words are not very common. [Oxford Dictionaries](https://en.oxforddictionaries.com/explore/how-many-words-are-there-in-the-english-language) lists over 171,000 currently used English words, but as we saw, only a few words show up in more than a few profiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect:\n",
    "In the space below, respond to each of these questions:\n",
    "1. What did you learn about the role of gender and self presentation in online dating from this lab? Write a paragraph.\n",
    "2. What trait did you pick for the Try It Yourself part at the end? What did you learn about how people who differ in this trait vary in their presentations of self? Why might that be? Write a paragraph.\n",
    "3. We made a number of choices along the way: which stop words to exclude, whether to \"stem\" words, and more. Pick one of these choices and say how you think our findings might have been different if we made a different choice. Write a few sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔 **Write your responses here:**\n",
    "....\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
